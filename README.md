# Calico-DSCP-Controller
A kubernetes controller that support traffic prioritization with DSCP marking.
Support [Calico](https://github.com/projectcalico/calico) or other iptables based CNI.

## Prerequisites

Before you try out this controller, you need to prepare:
- A kubernetes cluster with calico installed
- Nodes are connected by a network switch that supports DSCP marking
- The network switch need to be configured about DSCP marking rule , for example:
  - dscp-to-tc mapping
  - tc-to-queue mapping
  - scheduler strategy
  And bind the DSCP marking rule to the network interface, configuration might vary from different network switch vendors.

## How to install

1. Install the controller

```
kubectl apply -f https://raw.githubusercontent.com/owenowenisme/calico-dscp-controller/refs/heads/main/dscp-deployment.yaml
```

2. Deploy the configmap 
```
kubectl apply -f https://raw.githubusercontent.com/owenowenisme/calico-dscp-controller/refs/heads/main/configmap.yaml
```
You can modified the dscp priority of namespace by changing the value in configmap.

3. The system will create a DaemonSet named `k8s-dscp` and deploy pods named `k8s-dscp-xxxxx` to each node.

```bash
$ kubectl get ds -n kube-system
NAME          DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE
calico-node   4         4         4       4            4           kubernetes.io/os=linux   3d18h
k8s-dscp      3         3         3       3            3           <none>                   12h
kube-proxy    4         4         4       4            4           kubernetes.io/os=linux   3d18h
```

```bash
$ kubectl get pods -l daemonset-owner=k8s-dscp -n kube-system -o wide
NAME             READY   STATUS    RESTARTS   AGE   IP          NODE                   
k8s-dscp-2p9dk   1/1     Running   0          12h   10.6.8.83   k8sworker2.example.net  
k8s-dscp-nzwjv   1/1     Running   0          12h   10.6.8.84   k8sworker3.example.net   
k8s-dscp-vcqvl   1/1     Running   0          12h   10.6.8.81   k8sworker1.example.net  
```

## System Architecture
This project implemented a Kubernetes controller that, when deployed, creates a DaemonSet within the cluster. This DaemonSet is responsible for ensuring that our DSCP pods are always running on all nodes, and automatically restores them when these pods disappear due to certain factors.

Through these pods, we can control the iptables rules on each node, enabling packets generated by pods in our target applications to be tagged with DSCP labels before being sent out from the node.
![System Architecture](https://github.com/user-attachments/assets/a46c1f5e-1c5c-4d1c-a58e-00409c16df22)

When network switches receive packets with DSCP labels, they determine which queue to place them in based on the priority values pre-configured on the switch. The queue with the highest priority will be sent out first, while packets with lower priority are more likely to be dropped.

Through custom prioritization, we gain greater flexibility in deciding which applications are most important when running in highly congested clusters. This can significantly improve the efficiency of specified applications in distributed systems, such as distributed machine learning.


![SysSwitch Queue Mapping](https://github.com/user-attachments/assets/03b241eb-bf47-459f-9370-8fc2b3acf144)

## Results

We evaluated the controller's performance using [Ray](https://github.com/ray-project/ray), a popular distributed machine learning framework, to train an MNIST model.

Our test setup consisted of a Ray cluster deployed via [Kuberay](https://github.com/ray-project/kuberay), comprising one head node and three worker nodes, with each worker node allocated 5 CPUs. 

To simulate network congestion conditions, we used iperf3 to generate sustained traffic of 1 Gbps from a client to the server. Additionally, we modified the [example script](https://github.com/owenowenisme/calico-dscp-controller/blob/main/ray/ray_train_pytorch_mnist.py) from Ray's documentation by increasing the number of workers, which intensified inter-node network communication during training.

![image](https://github.com/user-attachments/assets/01fc5184-9f2a-404a-8482-525564a973d1)


The complete results and analysis are available [here](https://github.com/owenowenisme/calico-dscp-controller/tree/main/ray/result).

These results demonstrate that our DSCP controller can effectively mitigate the impact of network congestion on distributed machine learning workloads by intelligently prioritizing critical application traffic.


